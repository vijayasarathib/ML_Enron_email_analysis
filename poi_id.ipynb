{
 "metadata": {
  "name": "",
  "signature": "sha256:88f372b6b35a4a3726ab561b949699113112d544f3a1529f7454b77b31a503e6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "import matplotlib.pyplot as plt \n",
      "import sys\n",
      "import pickle\n",
      "from sklearn import preprocessing \n",
      "from time import time \n",
      "from sklearn.naive_bayes import GaussianNB \n",
      "from sklearn.metrics import accuracy_score \n",
      "from sklearn.metrics import precision_score \n",
      "from sklearn.metrics import recall_score \n",
      "from sklearn.grid_search import GridSearchCV \n",
      "\n",
      "sys.path.append(\"../tools/\")\n",
      "\n",
      "from feature_format import featureFormat, targetFeatureSplit\n",
      "from tester import test_classifier, dump_classifier_and_data\n",
      "\n",
      "### Task 1: Select what features you'll use.\n",
      "### features_list is a list of strings, each of which is a feature name.\n",
      "### The first feature must be \"poi\".\n",
      "##features_list = ['poi','salary'] # You will need to use more features\n",
      "\n",
      "features_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", 'shared_receipt_with_poi']\n",
      "\n",
      "### Load the dictionary containing the dataset\n",
      "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 2: Remove outliers\n",
      "features = [\"salary\", \"bonus\"] \n",
      "data_dict.pop('TOTAL', 0) \n",
      "data = featureFormat(data_dict, features) \n",
      "\n",
      "outliers = [] \n",
      "for key in data_dict: \n",
      "    val = data_dict[key]['salary'] \n",
      "    if val == 'NaN': \n",
      "        continue \n",
      "    outliers.append((key, int(val))) \n",
      " \n",
      " \n",
      "outliers_final = (sorted(outliers,key=lambda x:x[1],reverse=True)[:4]) \n",
      "\n",
      "### top 4 salaries \n",
      "print outliers_final \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('SKILLING JEFFREY K', 1111258), ('LAY KENNETH L', 1072321), ('FREVERT MARK A', 1060932), ('PICKERING MARK R', 655037)]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### plot the features \n",
      "for point in data: \n",
      "     salary = point[0] \n",
      "     bonus = point[1] \n",
      "     plt.scatter( salary, bonus ) \n",
      " \n",
      " \n",
      "plt.xlabel(\"salary\") \n",
      "plt.ylabel(\"bonus\") \n",
      "plt.show() \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### create new features \n",
      "### new features are: fraction_to_poi_email,fraction_from_poi_email \n",
      " \n",
      "def dict_to_list(key,normalizer): \n",
      "     new_list=[]  \n",
      "     for i in data_dict: \n",
      "         if data_dict[i][key]==\"NaN\" or data_dict[i][normalizer]==\"NaN\": \n",
      "             new_list.append(0.) \n",
      "         elif data_dict[i][key]>=0: \n",
      "             new_list.append(float(data_dict[i][key])/float(data_dict[i][normalizer])) \n",
      "     return new_list "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### create the new features list\n",
      "fraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\") \n",
      "fraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\") \n",
      " \n",
      "### insert new features into data_dict \n",
      "count=0 \n",
      "for i in data_dict: \n",
      "     data_dict[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[count] \n",
      "     data_dict[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[count] \n",
      "     count +=1 \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### store to my_dataset for easy export below \n",
      "my_dataset = data_dict \n",
      " \n",
      "### these two lines extract the features specified in features_list \n",
      "### and extract them from data_dict, returning a numpy array \n",
      "data = featureFormat(my_dataset, features_list)  #sort_keys = True)\n",
      "\n",
      "### plot new features \n",
      "for point in data: \n",
      "    from_poi = point[1] \n",
      "    to_poi = point[2] \n",
      "    plt.scatter( from_poi, to_poi ) \n",
      "    if point[0] == 1: \n",
      "       plt.scatter(from_poi, to_poi, color=\"r\", marker=\"*\") \n",
      "plt.xlabel(\"fraction of emails this person gets from poi\") \n",
      "plt.show() \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### if you are creating new features, could also do that here \n",
      "### split into labels and features (this line assumes that the first \n",
      "### feature in the array is the label, which is why \"poi\" must always \n",
      "### be first in features_list \n",
      "labels, features = targetFeatureSplit(data) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### machine learning process\n",
      " \n",
      " \n",
      "### deploying feature selection \n",
      "from sklearn import cross_validation \n",
      "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42) \n",
      "\n",
      " \n",
      "### use KFold for split and validate algorithm \n",
      "from sklearn.cross_validation import KFold \n",
      "kf=KFold(len(labels),3) \n",
      "for train_indices, test_indices in kf: \n",
      "    #make training and testing sets \n",
      "     features_train= [features[ii] for ii in train_indices] \n",
      "     features_test= [features[ii] for ii in test_indices] \n",
      "     labels_train=[labels[ii] for ii in train_indices] \n",
      "     labels_test=[labels[ii] for ii in test_indices] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier  \n",
      "t0 = time() \n",
      "clf = DecisionTreeClassifier() \n",
      "clf.fit(features_train,labels_train) \n",
      "score = clf.score(features_test,labels_test) \n",
      "print 'accuracy before tuning ', score \n",
      "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\" \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy before tuning  0.857142857143\n",
        "Decision tree algorithm time: 0.015 s\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = clf.feature_importances_ \n",
      "import numpy as np \n",
      "indices = np.argsort(importances)[::-1] \n",
      "#print 'Feature Ranking: ' \n",
      "#for i in range(16): \n",
      "#    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### try Naive Bayes for prediction \n",
      "t0 = time() \n",
      "\n",
      "clf = GaussianNB() \n",
      "clf.fit(features_train, labels_train) \n",
      "pred = clf.predict(features_test) \n",
      "accuracy = accuracy_score(pred,labels_test) \n",
      "print accuracy \n",
      " \n",
      " \n",
      "print \"NB algorithm time:\", round(time()-t0, 3), \"s\" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.857142857143\n",
        "NB algorithm time: 0.0 s\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### use manual tuning parameter min_samples_split \n",
      "t0 = time() \n",
      "clf = DecisionTreeClassifier(min_samples_split=5) \n",
      "clf = clf.fit(features_train,labels_train) \n",
      "pred= clf.predict(features_test) \n",
      "print(\"done in %0.3fs\" % (time() - t0))  \n",
      "\n",
      "acc=accuracy_score(labels_test, pred) \n",
      "\n",
      "print \"Validating algorithm:\" \n",
      "print \"accuracy after tuning = \", acc \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done in 0.000s\n",
        "Validating algorithm:\n",
        "accuracy after tuning =  0.928571428571\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function for calculation ratio of true positives \n",
      "# out of all positives (true + false) \n",
      "print 'precision = ', precision_score(labels_test,pred) \n",
      "\n",
      " \n",
      "# function for calculation ratio of true positives \n",
      "# out of true positives and false negatives \n",
      "print 'recall = ', recall_score(labels_test,pred) \n",
      " \n",
      "\n",
      "\n",
      "### dump your classifier, dataset and features_list so \n",
      "### anyone can run/check your results \n",
      "###dump_classifier_and_data(clf, my_dataset, features_list)\n",
      "\n",
      "pickle.dump(clf, open(\"my_classifier.pkl\", \"w\") ) \n",
      "pickle.dump(data_dict, open(\"my_dataset.pkl\", \"w\") ) \n",
      "pickle.dump(features_list, open(\"my_feature_list.pkl\", \"w\") ) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "precision =  0.666666666667\n",
        "recall =  0.666666666667\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}